# -Throughput-Driven-Vertical-Handover-Prediction-for-Mobile-Networks
This repository contains the code underpinning my BSc dissertation; Throughput-Driven Vertical Handover Prediction for Mobile Networks.

The project was performed on two datasets. An initial dataset contained data on throughput and signal strength from 4G and 5G networks, while a validation dataset contained data on throughput and signal strength from 3G and 4G networks. Each dataset is split into three subsets for experimentation: the "Throughput" subset, containing uplink and downlink throughput variables, the "Status Quo" subset, containing signal strength variables, and the "Combined" subset, containing both together.

The datasets, data preprocessing and models for each dataset are contained within a folder. The folder for the initial dataset is named "Initial Dataset", while the folder for the validation dataset is named "Validation Dataset".

For the initial dataset, the initial dataset file is entitled "Throughput Tests - Speedtest - Active Measurements.csv" (this is contained within a zip file, "Dataset.zip", due to its size breaching upload limits: this can be extracted for use.). The code snippet "[Subset] Dataset Filtering.py" should firstly be run for each of the 3 subsets to filter the dataset adequately and create the subsets, and "Sorting and Filling [Subset] Dataset.py" should then be run for each subset to ensure that all values have been correctly imputed for each timestamp. The final cleaned data for each subset is within the file "Final [Subset] Dataset.csv". These steps must be undertaken prior to running the models themselves.

For the validation dataset, the dataset is split into five directories according to mode of transport: Static, Train, Pedestrian, Car and Bus. For each, the code snippet "Combining [TransportMode] Dataset.py" must firstly be executed so that all of the constituent spreadsheets for each are merged. After this, the code snippet "Cleaning [TransportMode] Data ([Subset]).py" must be executed for each transport mode and subset to ensure that the data is clean and segregated into subsets adequately. The code snippet "Combining All Data ([Subset]).py" must then be executed for each subset to ensure that the data for each transport mode is combined, and the code snippet "Filtering Combined Dataset ([Subset]).py" should finally be run to produce the three final cleaned subsets. These steps must be undertaken prior to running the models themselves.

For each dataset, there is a Random Forest, a Neural Network and a Naive-Bayes Classifier built on the status quo subset to test for which model performs best. Then, there are Random Forest models built upon the throughput and combined datasets, as well as tests of numerous different tree numbers and maximum depths of Random Forest.

The core thesis that was written is also embedded, under the filename "Dissertation.docx".
